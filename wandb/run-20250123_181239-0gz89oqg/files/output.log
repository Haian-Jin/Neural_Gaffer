01/23/2025 18:12:40 - INFO - __main__ - ***** Running training *****
01/23/2025 18:12:40 - INFO - __main__ -   Num examples = 90092
01/23/2025 18:12:40 - INFO - __main__ -   Num batches each epoch = 704
01/23/2025 18:12:40 - INFO - __main__ -   Num Epochs = 114
01/23/2025 18:12:40 - INFO - __main__ -   Instantaneous batch size per device = 64
01/23/2025 18:12:40 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 128
01/23/2025 18:12:40 - INFO - __main__ -   Gradient Accumulation steps = 1
01/23/2025 18:12:40 - INFO - __main__ -   Total optimization steps = 80000
01/23/2025 18:12:40 - INFO - __main__ -  do_classifier_free_guidance = True
01/23/2025 18:12:40 - INFO - __main__ -  conditioning_dropout_prob = 0.05
Checkpoint 'latest' does not exist. Starting a new training run.
Steps:   0%|                                                                                                                                                            | 0/80000 [00:00<?, ?it/s]Traceback (most recent call last):
  File "/share/phoenix/nfs02/S6/localdisk/hj453/.conda/envs/neural-gaffer/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1131, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/share/phoenix/nfs02/S6/localdisk/hj453/.conda/envs/neural-gaffer/lib/python3.9/queue.py", line 179, in get
    raise Empty
_queue.Empty

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/share/phoenix/nfs02/S6/localdisk/hj453/code/Neural_Gaffer/neural_gaffer_training.py", line 1265, in <module>
    main(args)
  File "/share/phoenix/nfs02/S6/localdisk/hj453/code/Neural_Gaffer/neural_gaffer_training.py", line 966, in main
    for step, batch in enumerate(train_dataloader):
  File "/share/phoenix/nfs02/S6/localdisk/hj453/.conda/envs/neural-gaffer/lib/python3.9/site-packages/accelerate/data_loader.py", line 448, in __iter__
    current_batch = next(dataloader_iter)
  File "/share/phoenix/nfs02/S6/localdisk/hj453/.conda/envs/neural-gaffer/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 630, in __next__
    data = self._next_data()
  File "/share/phoenix/nfs02/S6/localdisk/hj453/.conda/envs/neural-gaffer/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1327, in _next_data
    idx, data = self._get_data()
  File "/share/phoenix/nfs02/S6/localdisk/hj453/.conda/envs/neural-gaffer/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1283, in _get_data
    success, data = self._try_get_data()
  File "/share/phoenix/nfs02/S6/localdisk/hj453/.conda/envs/neural-gaffer/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1144, in _try_get_data
    raise RuntimeError(f'DataLoader worker (pid(s) {pids_str}) exited unexpectedly') from e
RuntimeError: DataLoader worker (pid(s) 2644815) exited unexpectedly
[rank0]: Traceback (most recent call last):
[rank0]:   File "/share/phoenix/nfs02/S6/localdisk/hj453/.conda/envs/neural-gaffer/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1131, in _try_get_data
[rank0]:     data = self._data_queue.get(timeout=timeout)
[rank0]:   File "/share/phoenix/nfs02/S6/localdisk/hj453/.conda/envs/neural-gaffer/lib/python3.9/queue.py", line 179, in get
[rank0]:     raise Empty
[rank0]: _queue.Empty

[rank0]: The above exception was the direct cause of the following exception:

[rank0]: Traceback (most recent call last):
[rank0]:   File "/share/phoenix/nfs02/S6/localdisk/hj453/code/Neural_Gaffer/neural_gaffer_training.py", line 1265, in <module>
[rank0]:     main(args)
[rank0]:   File "/share/phoenix/nfs02/S6/localdisk/hj453/code/Neural_Gaffer/neural_gaffer_training.py", line 966, in main
[rank0]:     for step, batch in enumerate(train_dataloader):
[rank0]:   File "/share/phoenix/nfs02/S6/localdisk/hj453/.conda/envs/neural-gaffer/lib/python3.9/site-packages/accelerate/data_loader.py", line 448, in __iter__
[rank0]:     current_batch = next(dataloader_iter)
[rank0]:   File "/share/phoenix/nfs02/S6/localdisk/hj453/.conda/envs/neural-gaffer/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 630, in __next__
[rank0]:     data = self._next_data()
[rank0]:   File "/share/phoenix/nfs02/S6/localdisk/hj453/.conda/envs/neural-gaffer/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1327, in _next_data
[rank0]:     idx, data = self._get_data()
[rank0]:   File "/share/phoenix/nfs02/S6/localdisk/hj453/.conda/envs/neural-gaffer/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1283, in _get_data
[rank0]:     success, data = self._try_get_data()
[rank0]:   File "/share/phoenix/nfs02/S6/localdisk/hj453/.conda/envs/neural-gaffer/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1144, in _try_get_data
[rank0]:     raise RuntimeError(f'DataLoader worker (pid(s) {pids_str}) exited unexpectedly') from e
[rank0]: RuntimeError: DataLoader worker (pid(s) 2644815) exited unexpectedly
